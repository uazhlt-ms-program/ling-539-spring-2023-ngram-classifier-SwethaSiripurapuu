{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a25678c9993c1c2bbf0167f2ff03c982",
     "grade": false,
     "grade_id": "header-instructions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Tips\n",
    "- To avoid unpleasant surprises, I suggest you _run all cells in their order of appearance_ (__Cell__ $\\rightarrow$ __Run All__).\n",
    "\n",
    "\n",
    "- If the changes you've made to your solution don't seem to be showing up, try running __Kernel__ $\\rightarrow$ __Restart & Run All__ from the menu.\n",
    "\n",
    "\n",
    "- Before submitting your assignment, make sure everything runs as expected. First, restart the kernel (from the menu, select __Kernel__ $\\rightarrow$ __Restart__) and then **run all cells** (from the menu, select __Cell__ $\\rightarrow$ __Run All__).\n",
    "\n",
    "## Reminder\n",
    "\n",
    "- Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name, UA email, and collaborators below:\n",
    "\n",
    "\n",
    "\n",
    "Several of the cells in this notebook are **read only** to ensure instructions aren't unintentionally altered.  \n",
    "\n",
    "If you can't edit the cell, it is probably intentional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "# University of Arizona email address\n",
    "EMAIL = \"\"\n",
    "# Names of any collaborators.  Write N/A if none.\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0783621da2f047c6360f2ec0d56f121c",
     "grade": false,
     "grade_id": "cell-e35b85c2416e40f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Scratchpad\n",
    "\n",
    "You are welcome to create new cells (see the __Cell__ menu) to experiment and debug your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c80ac423030cfa372644d7cd456061af",
     "grade": false,
     "grade_id": "cell-955f8133afe96b26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e07f9ac61f4be6a57b6961cde23a6d58",
     "grade": false,
     "grade_id": "cell-a2292c2fbc4cf52e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Mini Python tutorial\n",
    "\n",
    "This course uses Python 3.8.\n",
    "\n",
    "Below is a very basic (and incomplete) overview of the Python language... \n",
    "\n",
    "For those completely new to Python, [this section of the official documentation may be useful](https://docs.python.org/3.8/library/stdtypes.html#common-sequence-operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfcd9f827d4855d02514b2e54ba32077",
     "grade": false,
     "grade_id": "cell-d6593132353238c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a comment.  \n",
    "# Any line starting with # will be interpreted as a comment\n",
    "\n",
    "# this is a string assigned to a variable\n",
    "greeting = \"hello\"\n",
    "\n",
    "# If enclosed in triple quotes, strings can also be multiline:\n",
    "\n",
    "\"\"\"\n",
    "I'm a multiline\n",
    "string.\n",
    "\"\"\"\n",
    "\n",
    "# let's use a for loop to print it letter by letter\n",
    "for letter in greeting:\n",
    "    print(letter)\n",
    "    \n",
    "# Did you notice the indentation there?  Whitespace matters in Python!\n",
    "\n",
    "# here's a list of integers\n",
    "\n",
    "numbers = [1, 2, 3, 4]\n",
    "\n",
    "# let's add one to each number using a list comprehension\n",
    "# and assign the result to a variable called res\n",
    "# list comprehensions are used widely in Python (they're very Pythonic!)\n",
    "\n",
    "res = [num + 1 for num in numbers]\n",
    "\n",
    "# let's confirm that it worked\n",
    "print(res)\n",
    "\n",
    "# now let's try spicing things up using a conditional to filter out all values greater than or equal to 3...\n",
    "print([num for num in res if not num >= 3])\n",
    "\n",
    "# Python 3.7 introduced \"f-strings\" as a convenient way of formatting strings using templates\n",
    "# For example ...\n",
    "name = \"Josuke\"\n",
    "\n",
    "print(f\"{greeting}, {name}!\")\n",
    "\n",
    "# f-strings are f-ing convenient!\n",
    "\n",
    "\n",
    "# let's look at defining functions in Python..\n",
    "\n",
    "def greet(name):\n",
    "    print(f\"Howdy, {name}!\")\n",
    "\n",
    "# here's how we call it...\n",
    "\n",
    "greet(\"partner\")\n",
    "\n",
    "# let's add a description of the function...\n",
    "\n",
    "def greet(name):\n",
    "    \"\"\"\n",
    "    Prints a greeting given some name.\n",
    "    \n",
    "    :param name: the name to be addressed in the greeting\n",
    "    :type name: str\n",
    "    \n",
    "    \"\"\"\n",
    "    print(f\"Howdy, {name}!\")\n",
    "    \n",
    "# I encourage you to use docstrings!\n",
    "\n",
    "# Python introduced support for optional type hints in v3.5.\n",
    "# You can read more aobut this feature here: https://docs.python.org/3.8/library/typing.html\n",
    "# let's give it a try...\n",
    "def add_six(num: int) -> int:\n",
    "    return num + 6\n",
    "\n",
    "# this should print 13\n",
    "print(add_six(7))\n",
    "\n",
    "# Python also has \"anonymous functions\" (also known as \"lambda\" functions)\n",
    "# take a look at the following code:\n",
    "\n",
    "greet_alt = lambda name: print(f\"Hi, {name}!\")\n",
    "\n",
    "greet_alt(\"Fred\")\n",
    "\n",
    "# lambda functions are often passed to other functions\n",
    "# For example, they can be used to specify how a sequence should be sorted\n",
    "# let's sort a list of pairs by their second element\n",
    "pairs = [(\"bounce\", 32), (\"bighorn\", 12), (\"radical\", 4), (\"analysis\", 7)]\n",
    "# -1 is last thing in some sequence, -2 is the second to last thing in some seq, etc.\n",
    "print(sorted(pairs, key=lambda pair: pair[-1]))\n",
    "\n",
    "# we can sort it by the first element instead\n",
    "# NOTE: python indexing is zero-based\n",
    "print(sorted(pairs, key=lambda pair: pair[0]))\n",
    "\n",
    "# You can learn more about other core data types and their methods here: \n",
    "# https://docs.python.org/3.8/library/stdtypes.html\n",
    "\n",
    "# Because of its extensive standard library, Python is often described as coming with \"batteries included\".  \n",
    "# Take a look at these \"batteries\": https://docs.python.org/3.8/library/\n",
    "\n",
    "# You now know enough to complete this homework assignment (or at least where to look)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9833c1ce55cdc8f894b287df328ab677",
     "grade": false,
     "grade_id": "test-imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Iterator, Iterable, List, Tuple, Text, Union\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import spmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f9a7e22714cd4819e5c3540627384cd",
     "grade": false,
     "grade_id": "random-seed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# An NDArray can either be a numpy array (np.ndarray) or a sparse matrix (spmatrix)\n",
    "NDArray = Union[np.ndarray, spmatrix]\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a90496aa4958e8d071d296eefc9a2bdb",
     "grade": false,
     "grade_id": "cell-f4a4e53967b8f695",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment overview\n",
    "\n",
    "In this assignment, you'll use a binomial logistic regression classifier with $n$-gram features to categorize SMS messages as **SPAM** or **NOT SPAM**.  \n",
    "\n",
    "You will not be required to implement logistic regression from scratch.  Instead, you may use the `scikit-learn` implementation.  Be sure to carefully read the comments in the code skeleton provided.  To earn full credit, all tests must pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27d101c9abd83942c4f956aadcf0b071",
     "grade": false,
     "grade_id": "needed-imports",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Add any needed imports from sklearn here! See the comments/hints below for\n",
    "#  tips that will guide you to what to add here.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7c72a4e0f790e0ca25b37d3db6139db",
     "grade": false,
     "grade_id": "md-read-smsspam",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## `.read_smsspam()`\n",
    "\n",
    "First we'll need data for training and evaluating our classifier.\n",
    "\n",
    "Complete the function below which takes a path to a file (stored under `data` in the docker image) and returns a sequence of (label, text) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7257ac60f5c5b2fcb7413e967cda841",
     "grade": false,
     "grade_id": "code-read-smsspam",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_smsspam(smsspam_path: Text) -> Iterator[Tuple[Text, Text]]:\n",
    "    \"\"\"\n",
    "    Generates (label, text) tuples from the lines in an SMSSpam file.\n",
    "\n",
    "    SMSSpam files contain one message per line. Each line is composed of a label\n",
    "    (ham or spam), a tab character, and the text of the SMS. Here are some\n",
    "    examples:\n",
    "\n",
    "      spam\t85233 FREE>Ringtone!Reply REAL\n",
    "      ham\tI can take you at like noon\n",
    "      ham\tWhere is it. Is there any opening for mca.\n",
    "\n",
    "    :param smsspam_path: The path of an SMSSpam file, formatted as above.\n",
    "    :return: An iterator over (label, text) tuples.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "090962f0ecf8cb76ed91165eee0dbdc3",
     "grade": false,
     "grade_id": "md-test-read-smsspam",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Test `.read_smsspam()` (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cd2867872d0662f97fc4f24bb99efb6",
     "grade": true,
     "grade_id": "test-read-smsspam",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# keep a counter here (instead of enumerate) in case the iterator is empty\n",
    "count = 0\n",
    "for example in read_smsspam(\"data/smsspam/SMSSpamCollection.train\"):\n",
    "\n",
    "    # make sure the right shape is returned\n",
    "    assert len(example) == 2\n",
    "    label, text = example\n",
    "\n",
    "    # make sure the label is one of the expected two\n",
    "    assert label in { \"ham\", \"spam\" }\n",
    "\n",
    "    count += 1\n",
    "\n",
    "# You should find exactly 3345 pairs in the training partition of the data\n",
    "assert count == 3345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d81129e4c91af384bdc832d4d1b7b75d",
     "grade": false,
     "grade_id": "md-texttofeatures",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## `TextToFeatures`\n",
    "\n",
    "Using the provided skeleton, complete the class `TextToFeatures` to transform text (documents) into real-valued features derived from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76e5b36d8cc671f467b24660dde9141c",
     "grade": false,
     "grade_id": "code-texttofeatures",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class TextToFeatures:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes an object for converting texts to features.    \n",
    "        \"\"\"\n",
    "        \n",
    "        # HINT: you may want to use a sklearn vectorizer. Be sure you've\n",
    "        #  worked through the sklearn tutorial in the course website and read\n",
    "        #  the documentation on sklearn's vectorizers at\n",
    "        # https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text\n",
    "        #\n",
    "        # Learning to use a library based only on reading its documentation\n",
    "        #  is one of the skills that we hope you'll learn in this course!\n",
    "        #\n",
    "        # If you take this approach, your code here will largely just be\n",
    "        #  calls to the corresponding methods of the sklearn vectorizer\n",
    "        #  that you choose. Don't forget to add the import statement\n",
    "        #  for your chosen vectorizer in the imports cell in the Assignment\n",
    "        #  Overview.\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def fit(self, training_texts: Iterable[Text]) -> None:\n",
    "        \"\"\"\n",
    "        Fits (\"trains\") a TextToFeature instance on a collection of documents.\n",
    "        \n",
    "        The provided training texts are analyzed to determine the vocabulary, \n",
    "        i.e., all feature values that the converter will support. \n",
    "        Each such feature value will be associated with a unique integer index \n",
    "        that may later be accessed via the .index() method.\n",
    "\n",
    "        It is up to the implementer exactly what features to produce from a\n",
    "        text, but the features will always include some single words and some\n",
    "        multi-word expressions (e.g., \"need\" and \"to you\").\n",
    "        \n",
    "        \n",
    "        docs = [\n",
    "            \"LOL. is this u? http://supersketchyurl.com/dangerous\",\n",
    "            \"The IRS has been trying to reach you.\",\n",
    "            \"Enclosed is your Coyote Joe's Marketplace Rewards Card.\"\n",
    "            \"Logan I'd like to add you to my professional network on LinkedIn\",\n",
    "        ]\n",
    "        \n",
    "        t2f = TextToFeatures()\n",
    "        t2f.fit(docs)\n",
    "\n",
    "        :param training_texts: The training texts.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "    def index(self, feature: Text) -> Union[None, int]:\n",
    "        \"\"\"\n",
    "        Returns the index in the vocabulary of the given feature value.  \n",
    "        If the features isn't present, return None.\n",
    "\n",
    "        :param feature: A feature\n",
    "        :return: The unique integer index associated with the feature or None if not present.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def transform(self, texts: Iterable[Text]) -> NDArray:\n",
    "        \"\"\"\n",
    "        Creates a feature matrix from a sequence of texts.\n",
    "        \n",
    "        docs = [\n",
    "            \"LOL. is this u? http://supersketchyurl.com/dangerous\",\n",
    "            \"The IRS has been trying to reach you.\",\n",
    "            \"Enclosed is your Coyote Joe's Marketplace Rewards Card.\"\n",
    "            \"I'd like to add you to my professional network on LinkedIn\",\n",
    "        ]\n",
    "        \n",
    "        t2f = TextToFeatures()\n",
    "        t2f.fit(docs)\n",
    "\n",
    "        # this produces a NDArray representing our features for the provided doc\n",
    "        t2f.transform([\"Let's meet at Coyote Joe's at 6.\"])\n",
    "\n",
    "\n",
    "        Each row of the matrix corresponds to one of the input texts. The value\n",
    "        at index j of row i is the value in the ith text of the feature\n",
    "        associated with the unique integer j.\n",
    "\n",
    "        It is up to the implementer what the value of a feature that is present\n",
    "        in a text should be, though a common choice is 1. Features that are\n",
    "        absent from a text will have the value 0.\n",
    "\n",
    "        :param texts: A sequence of texts.\n",
    "        :return: A matrix, with one row of feature values for each text.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a376f31db068c1e4e93a3a96b9df66b5",
     "grade": false,
     "grade_id": "md-test-texttofeatures",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Test features (7 pts)\n",
    "\n",
    "Let's test the behavior of your implementation of `TextToFeatures` (2 points for the first cell, 5 points for the second cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44a96b5e05f7712556a58cbeaa76fe29",
     "grade": true,
     "grade_id": "test-texttofeatures-1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "training_texts: List[Text] = [\n",
    "    \"LOL. is this u? http://supersketchyurl.com/dangerous\",\n",
    "    \"The IRS has been trying to reach you.\",\n",
    "    \"You won't believe what in this doc.  Click here to find out!\",\n",
    "    \"Enclosed is your Coyote Joe's Marketplace Rewards Card.\"\n",
    "    \"Logan I'd like to add you to my professional network on LinkedIn\",\n",
    "]\n",
    "    \n",
    "t2f = TextToFeatures()\n",
    "t2f.fit(training_texts)\n",
    "\n",
    "features = t2f.transform([\"Is Bill in your professional network?\"]).todense()\n",
    "# ensure there is one row of features for each sentence\n",
    "assert features.shape[0] == 1\n",
    "# ensure there are nonzero values for some selected unigram and bigram features\n",
    "assert t2f.index(\"reach\") is not None\n",
    "\n",
    "# if a feature wasn't observed during training, it should not have an index\n",
    "assert t2f.index(\"strawberry kangaroos\") is None\n",
    "assert t2f.index(\"Jason Mendoza\") is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80ea3c9f6daa0717ee68aaa280a35c44",
     "grade": true,
     "grade_id": "test-texttofeatures-2",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# get the texts from the training data\n",
    "examples: Iterable[Tuple[str, str]]  = read_smsspam(\"data/smsspam/SMSSpamCollection.train\")\n",
    "training_texts: List[str]            = [text for _, text in examples]\n",
    "\n",
    "# create the feature extractor from the training texts\n",
    "t2f = TextToFeatures()\n",
    "t2f.fit(training_texts)\n",
    "\n",
    "# extract features for some made-up sentences\n",
    "features = t2f.transform([\n",
    "    \"There are some things that I need to send to you.\",\n",
    "    \"Hello!\"\n",
    "]).todense()\n",
    "\n",
    "# make sure there is one row of features for each sentence\n",
    "assert len(features.shape) == 2\n",
    "n_rows, n_cols = features.shape\n",
    "assert n_rows == 2\n",
    "\n",
    "# make sure there are nonzero values for some selected unigram and bigram\n",
    "# features in the first sentence\n",
    "# If you're getting an error here: Did you create your features such that\n",
    "# the features that are checked here will actually be calculated?\n",
    "indices = [t2f.index(f) for f in [\"need\", \"to you\"]]\n",
    "assert len(set(indices)) > 1\n",
    "row_indices, col_indices = features[:, indices].nonzero()\n",
    "assert np.all(row_indices == 0)\n",
    "assert len(col_indices) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TextToLabels`\n",
    "Using the provided skeleton, complete the class `TextToLabels` to map class labels (strings) to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71242e515b99e8e1c7611135e31c0157",
     "grade": false,
     "grade_id": "code-texttolabels",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class TextToLabels:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes an object for converting texts to labels.\n",
    "        \"\"\"\n",
    "        \n",
    "        # HINT: As with the previous class, you may choose to use an sklearn\n",
    "        #  class here. See the documentation at\n",
    "        # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "        #\n",
    "        # As before, be sure to add an import statement for the sklearn class\n",
    "        #  that you choose in the (editable) import cell towards the top of\n",
    "        #  this notebook.\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def fit(self, training_labels: Iterable[Text]) -> None:\n",
    "        \"\"\"\n",
    "        Assigns each distinct label a unique integer.\n",
    "        \n",
    "        \n",
    "        Training labels are analyzed to determine the vocabulary, \n",
    "        i.e., all labels that the converter will support. \n",
    "        Each such label will be associated with a unique integer index \n",
    "        that may later be accessed via the .index() method.\n",
    "\n",
    "        :param training_labels: The training labels.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def index(self, label: Text) -> Union[None, int]:\n",
    "        \"\"\"Returns the index in the vocabulary of the given label.\n",
    "\n",
    "        :param label: A label\n",
    "        :return: The unique integer index associated with the label.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def transform(self, labels: Iterable[Text]) -> NDArray:\n",
    "        \"\"\"\n",
    "        Creates a label vector from a sequence of labels.\n",
    "\n",
    "        Each entry in the vector corresponds to one of the input labels. The\n",
    "        value at index j is the unique integer associated with the jth label.\n",
    "\n",
    "        :param labels: A sequence of labels.\n",
    "        :return: A vector, with one entry for each label.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        \n",
    "    def __contains__(self, label: Text) -> bool:\n",
    "        \"\"\"\n",
    "        Special \"dunder\" method to check if a label is known to the TextToLabels instance.\n",
    "        \n",
    "        labeler = TextToLabels()\n",
    "        labeler.fit([\"POSITIVE\", \"NEGATIVE\"])\n",
    "\n",
    "        # should be True:\n",
    "        \"POSITIVE\" in labeler \n",
    "        \n",
    "        # should be False:\n",
    "        \"MBOP\" in labeler\n",
    "        \n",
    "        :return: True if the label was seen in the training data; False otherwise\n",
    "        \"\"\"\n",
    "        # NOTE: you do not need to change this if you've implemented .index() correctly!\n",
    "        return False if self.index(label) is None else True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "990b356fba0ee2e4b7f1585a25aa6294",
     "grade": false,
     "grade_id": "md-test-texttolabels",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Test labels (7pts)\n",
    "\n",
    "2 points for the first testing cell, 5 points for the second cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46a9acdc3680ae11eae0bb7070762735",
     "grade": true,
     "grade_id": "test-texttolabels-1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "training_labels = [\"SPAM\", \"NOT_SPAM\"]\n",
    "lbl_encoder     = TextToLabels()\n",
    "lbl_encoder.fit(training_labels)\n",
    "\n",
    "assert \"SPAM\" in lbl_encoder\n",
    "assert lbl_encoder.index(\"SPAM\") is not None\n",
    "\n",
    "# this label wasn't seen in the training data labels\n",
    "assert \"DISSERTATION\" not in lbl_encoder\n",
    "assert lbl_encoder.index(\"DISSERTATION\") is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "297f9ee32baa3ab146ebdc9b7f4a79b0",
     "grade": true,
     "grade_id": "test-texttolabels-2",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_labels():\n",
    "    # get the texts from the training data\n",
    "    examples = read_smsspam(\"data/smsspam/SMSSpamCollection.train\")\n",
    "    labels = [label for label, _ in examples]\n",
    "\n",
    "    # create the label encoder from the training texts\n",
    "    lbl_encoder = TextToLabels()\n",
    "    lbl_encoder.fit(labels)\n",
    "\n",
    "    # just a simple convenience function to use for testing...\n",
    "    to_labels = lambda labels: lbl_encoder.transform(labels)\n",
    "    \n",
    "    # make sure that some sample labels are encoded as expected\n",
    "    ham_index = lbl_encoder.index(\"ham\")\n",
    "    spam_index = lbl_encoder.index(\"spam\")\n",
    "    assert ham_index != spam_index\n",
    "    assert np.all(\n",
    "        to_labels([\"ham\", \"spam\", \"spam\"]) == [ham_index, spam_index, spam_index]\n",
    "    )\n",
    "\n",
    "test_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3343935439326da0eda803a66ea6bbec",
     "grade": false,
     "grade_id": "cell-12ff0ecbb3bbcf93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# `Classifier`\n",
    "Using the provided skeleton, complete the class `Classifier` which will use `sklearn`'s logistic regression classifier.  You will implement the `train` and `predict` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b57ad680e093cc903edef9d04f6b362e",
     "grade": false,
     "grade_id": "cell-b30da2f58a08c088",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initalizes a logistic regression classifier.\n",
    "        \"\"\"\n",
    "\n",
    "        # HINT: See the documentation at\n",
    "        # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "        #  Think about the input parameter values you'll need to use.\n",
    "        #\n",
    "        # As before, be sure to add an import statement for the sklearn class\n",
    "        #  that you choose in the (editable) import cell towards the top of\n",
    "        #  this notebook.\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def train(self, features: NDArray, labels: NDArray) -> None:\n",
    "        \"\"\"\n",
    "        Trains the classifier using the given training examples.\n",
    "\n",
    "        :param features: A feature matrix, where each row represents a text.\n",
    "        Such matrices will typically be generated via TextToFeatures.\n",
    "        :param labels: A label vector, where each entry represents a label.\n",
    "        Such vectors will typically be generated via TextToLabels.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    # just an alias for \"train\"\n",
    "    fit = train\n",
    "    \n",
    "    def predict(self, features: NDArray) -> NDArray:\n",
    "        \"\"\"Makes predictions for each of the given examples.\n",
    "\n",
    "        :param features: A feature matrix, where each row represents a text.\n",
    "        Such matrices will typically be generated via TextToFeatures.\n",
    "        :return: A prediction vector, where each entry represents a label.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d671b943adde04ccfda6b75c2fca19c5",
     "grade": false,
     "grade_id": "md-min-f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Min F1 Score (4pts)\n",
    "\n",
    "If you've gotten to this point but you're not passing these tests, it indicates that your model performance could be improved. What can you do to alter your model above, so that its performace here can be improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a9164008cfad7c8bf9d8e1520c697a8",
     "grade": true,
     "grade_id": "test-predictions",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def no_peeking() -> bool:\n",
    "    train_data = set(read_smsspam(\"data/smsspam/SMSSpamCollection.train\"))\n",
    "    dev_data   = set(read_smsspam(\"data/smsspam/SMSSpamCollection.devel\"))\n",
    "    if len(train_data) < 10:\n",
    "        print(\"Something is wrong with the training data\")\n",
    "        return False\n",
    "    if len(dev_data) < 10:\n",
    "        print(\"Something is wrong with the dev data\")\n",
    "        return False\n",
    "    \n",
    "    for dev_ex in dev_data:\n",
    "        if dev_ex in train_data:\n",
    "            print(dev_ex)\n",
    "            print(\"Dev data should not overlap with train data!\")\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "def test_prediction() -> Tuple[int, int]:\n",
    "    # get texts and labels from the training data\n",
    "    train_examples = read_smsspam(\"data/smsspam/SMSSpamCollection.train\")\n",
    "    train_labels, train_texts = zip(*train_examples)\n",
    "\n",
    "    # get texts and labels from the development data\n",
    "    dev_examples = read_smsspam(\"data/smsspam/SMSSpamCollection.devel\")\n",
    "    dev_labels, dev_texts = zip(*dev_examples)\n",
    "\n",
    "    # fit/\"train\" the feature extractor and label encoder\n",
    "    to_features = TextToFeatures()\n",
    "    to_features.fit(train_texts)\n",
    "    to_labels   = TextToLabels()\n",
    "    to_labels.fit(train_labels)\n",
    "\n",
    "    # train the classifier on the training data\n",
    "    clf = Classifier()\n",
    "    clf.train(to_features.transform(train_texts), to_labels.transform(train_labels))\n",
    "\n",
    "    # make predictions on the development data\n",
    "    predicted_indices = clf.predict(to_features.transform(dev_texts))\n",
    "    assert np.array_equal(predicted_indices, predicted_indices.astype(bool))\n",
    "\n",
    "    # measure performance of predictions\n",
    "    dev_indices   = to_labels.transform(dev_labels)\n",
    "    spam_label    = to_labels.index(\"spam\")\n",
    "    f1            = f1_score(dev_indices, predicted_indices, pos_label=spam_label)\n",
    "    accuracy      = accuracy_score(dev_indices, predicted_indices)\n",
    "\n",
    "    print(f\"\\n{f1:.1%} F1 and {accuracy:.1%} accuracy on SMSSpam development data\")\n",
    "    return f1, accuracy\n",
    "\n",
    "\n",
    "# ensure the train and dev data is well-formed\n",
    "assert no_peeking() is True, \"Problem with train and/or dev data\"\n",
    "\n",
    "# make sure that performance is adequate\n",
    "f1, accuracy = test_prediction()\n",
    "min_f1, min_accuracy = 0.89, 0.97\n",
    "\n",
    "assert accuracy > min_accuracy, f\"accuracy {accuracy:.1%} did not exceed {min_accuracy:.1%}\"\n",
    "assert f1 > min_f1, f\"f1 {f1:.1%} did not exceed {min_f1:.1%}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c9883f350c5ce553fc21e1d243a17e06",
     "grade": false,
     "grade_id": "md-high-f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## High F1 score (2 pts)\n",
    "\n",
    "Adjust your classifier (ex. features, regularization, etc.) as needed to achieve a minimum F1 score of 0.94."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "051ea0d41df17b64cc0c21778a668335",
     "grade": true,
     "grade_id": "test-high-performance",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "f1, accuracy = test_prediction()\n",
    "\n",
    "min_f1, min_accuracy = 0.94, 0.98\n",
    "# make sure that performance is adequate\n",
    "assert accuracy > min_accuracy, f\"accuracy {accuracy:.2%} did not exceed {min_accuracy:.2%}\"\n",
    "assert f1 > min_f1, f\"f1 {f1:.2%} did not exceed {min_f1:.2%}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
